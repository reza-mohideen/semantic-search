{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>article</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOCD Support Groups: Finding Help and Hope in ...</td>\n",
       "      <td>h1</td>\n",
       "      <td>title</td>\n",
       "      <td>/blog/nocd-support-groups-finding-help-and-hop...</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One of the most helpful things in my own recov...</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/blog/nocd-support-groups-finding-help-and-hop...</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is something powerful about knowing that...</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/blog/nocd-support-groups-finding-help-and-hop...</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support is a key piece of your recovery journe...</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/blog/nocd-support-groups-finding-help-and-hop...</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support groups may help you realize that you a...</td>\n",
       "      <td>p</td>\n",
       "      <td>You are not alone</td>\n",
       "      <td>/blog/nocd-support-groups-finding-help-and-hop...</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text tag          paragraph  \\\n",
       "0  NOCD Support Groups: Finding Help and Hope in ...  h1              title   \n",
       "1  One of the most helpful things in my own recov...   p                NaN   \n",
       "2  There is something powerful about knowing that...   p                NaN   \n",
       "3  Support is a key piece of your recovery journe...   p                NaN   \n",
       "5  Support groups may help you realize that you a...   p  You are not alone   \n",
       "\n",
       "                                             article  num_words  num_sentences  \n",
       "0  /blog/nocd-support-groups-finding-help-and-hop...         11              1  \n",
       "1  /blog/nocd-support-groups-finding-help-and-hop...         56              5  \n",
       "2  /blog/nocd-support-groups-finding-help-and-hop...         60              4  \n",
       "3  /blog/nocd-support-groups-finding-help-and-hop...         78              4  \n",
       "5  /blog/nocd-support-groups-finding-help-and-hop...         85              5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "blogs_df = pd.read_csv('../datasets/blogs.csv', index_col=0)\n",
    "blogs_df = blogs_df[blogs_df['num_words'] > 7]\n",
    "blogs_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(df):\n",
    "    passages = []\n",
    "    for index, row in df.iterrows():\n",
    "        passages.append(row['text'])\n",
    "\n",
    "    return passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n",
      "{'dimension': 2048,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "index = pinecone.Index('nocd-search-huggingface')\n",
    "index.delete(deleteAll=True)\n",
    "print(index.describe_index_stats())\n",
    "\n",
    "index = pinecone.Index('nocd-search-openai')\n",
    "index.delete(deleteAll=True)\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:41<00:00,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 4373}},\n",
      " 'total_vector_count': 4373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# upsert using sentence transformer model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'msmarco-distilbert-base-tas-b'\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.max_seq_length = 256\n",
    "\n",
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "# create a new index if does not already exist\n",
    "print('Creating index...')\n",
    "if 'nocd-search-huggingface' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'nocd-search-huggingface',\n",
    "        dimension=model.get_sentence_embedding_dimension(),\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('nocd-search-huggingface')\n",
    "\n",
    "passages = get_text(blogs_df)  # generator that loads (query, passage) pairs\n",
    "blogs_df = blogs_df.replace({np.nan: ''})\n",
    "\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(passages), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(passages))\n",
    "    # get batch of lines and IDs\n",
    "    passage_batch = passages[i: i+batch_size]\n",
    "    ids_batch = [f\"{str(n)}_{model_name}\" for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    embeds = model.encode(passage_batch).tolist()\n",
    "    # prep metadata and upsert batch\n",
    "    metadata = [\n",
    "        {\n",
    "            'text': passage, \n",
    "            'paragraph_name': blogs_df[blogs_df['text'] == passage].iloc[0]['paragraph'], \n",
    "            'article_name': blogs_df[blogs_df['text'] == passage].iloc[0]['article'], \n",
    "            'model': model_name\n",
    "        } \n",
    "        for passage in passage_batch\n",
    "    ]\n",
    "    to_upsert = zip(ids_batch, embeds, metadata)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))\n",
    "\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:42<00:00,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 8746}},\n",
      " 'total_vector_count': 8746}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# upsert using sentence transformer model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'all-distilroberta-v1'\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.max_seq_length = 256\n",
    "\n",
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "# create a new index if does not already exist\n",
    "print('Creating index...')\n",
    "if 'nocd-search-huggingface' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'nocd-search-huggingface',\n",
    "        dimension=model.get_sentence_embedding_dimension(),\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('nocd-search-huggingface')\n",
    "\n",
    "passages = get_text(blogs_df)  # generator that loads (query, passage) pairs\n",
    "blogs_df = blogs_df.replace({np.nan: ''})\n",
    "\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(passages), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(passages))\n",
    "    # get batch of lines and IDs\n",
    "    passage_batch = passages[i: i+batch_size]\n",
    "    ids_batch = [f\"{str(n)}_{model_name}\" for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    embeds = model.encode(passage_batch).tolist()\n",
    "    # prep metadata and upsert batch\n",
    "    metadata = [\n",
    "        {\n",
    "            'text': passage, \n",
    "            'paragraph_name': blogs_df[blogs_df['text'] == passage].iloc[0]['paragraph'], \n",
    "            'article_name': blogs_df[blogs_df['text'] == passage].iloc[0]['article'], \n",
    "            'model': model_name\n",
    "        } \n",
    "        for passage in passage_batch\n",
    "    ]\n",
    "    to_upsert = zip(ids_batch, embeds, metadata)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))\n",
    "\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:54<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 13119}},\n",
      " 'total_vector_count': 13119}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# upsert using sentence transformer model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'all-mpnet-base-v2'\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.max_seq_length = 256\n",
    "\n",
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "# create a new index if does not already exist\n",
    "print('Creating index...')\n",
    "if 'nocd-search-huggingface' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'nocd-search-huggingface',\n",
    "        dimension=model.get_sentence_embedding_dimension(),\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('nocd-search-huggingface')\n",
    "\n",
    "passages = get_text(blogs_df)  # generator that loads (query, passage) pairs\n",
    "blogs_df = blogs_df.replace({np.nan: ''})\n",
    "\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(passages), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(passages))\n",
    "    # get batch of lines and IDs\n",
    "    passage_batch = passages[i: i+batch_size]\n",
    "    ids_batch = [f\"{str(n)}_{model_name}\" for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    embeds = model.encode(passage_batch).tolist()\n",
    "    # prep metadata and upsert batch\n",
    "    metadata = [\n",
    "        {\n",
    "            'text': passage, \n",
    "            'paragraph_name': blogs_df[blogs_df['text'] == passage].iloc[0]['paragraph'], \n",
    "            'article_name': blogs_df[blogs_df['text'] == passage].iloc[0]['article'], \n",
    "            'model': model_name\n",
    "        } \n",
    "        for passage in passage_batch\n",
    "    ]\n",
    "    to_upsert = zip(ids_batch, embeds, metadata)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))\n",
    "\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 737/737 [00:00<00:00, 301kB/s]\n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 136kB/s]\n",
      "Downloading: 100%|██████████| 9.46k/9.46k [00:00<00:00, 6.75MB/s]\n",
      "Downloading: 100%|██████████| 523/523 [00:00<00:00, 318kB/s]\n",
      "Downloading: 100%|██████████| 116/116 [00:00<00:00, 60.5kB/s]\n",
      "Downloading: 100%|██████████| 25.5k/25.5k [00:00<00:00, 802kB/s]\n",
      "Downloading: 100%|██████████| 265M/265M [00:06<00:00, 39.1MB/s] \n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 31.8kB/s]\n",
      "Downloading: 100%|██████████| 112/112 [00:00<00:00, 73.7kB/s]\n",
      "Downloading: 100%|██████████| 466k/466k [00:00<00:00, 2.80MB/s]\n",
      "Downloading: 100%|██████████| 333/333 [00:00<00:00, 294kB/s]\n",
      "Downloading: 100%|██████████| 13.8k/13.8k [00:00<00:00, 416kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 1.71MB/s]\n",
      "Downloading: 100%|██████████| 349/349 [00:00<00:00, 334kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:44<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 768,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 17492}},\n",
      " 'total_vector_count': 17492}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# upsert using sentence transformer model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'multi-qa-distilbert-cos-v1'\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.max_seq_length = 256\n",
    "\n",
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "# create a new index if does not already exist\n",
    "print('Creating index...')\n",
    "if 'nocd-search-huggingface' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'nocd-search-huggingface',\n",
    "        dimension=model.get_sentence_embedding_dimension(),\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('nocd-search-huggingface')\n",
    "\n",
    "passages = get_text(blogs_df)  # generator that loads (query, passage) pairs\n",
    "blogs_df = blogs_df.replace({np.nan: ''})\n",
    "\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(passages), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(passages))\n",
    "    # get batch of lines and IDs\n",
    "    passage_batch = passages[i: i+batch_size]\n",
    "    ids_batch = [f\"{str(n)}_{model_name}\" for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    embeds = model.encode(passage_batch).tolist()\n",
    "    # prep metadata and upsert batch\n",
    "    metadata = [\n",
    "        {\n",
    "            'text': passage, \n",
    "            'paragraph_name': blogs_df[blogs_df['text'] == passage].iloc[0]['paragraph'], \n",
    "            'article_name': blogs_df[blogs_df['text'] == passage].iloc[0]['article'], \n",
    "            'model': model_name\n",
    "        } \n",
    "        for passage in passage_batch\n",
    "    ]\n",
    "    to_upsert = zip(ids_batch, embeds, metadata)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))\n",
    "\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:34<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 4373}},\n",
      " 'total_vector_count': 4373}\n"
     ]
    }
   ],
   "source": [
    "# upsert using sentence transformer model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "model.max_seq_length = 256\n",
    "\n",
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "# create a new index if does not already exist\n",
    "print('Creating index...')\n",
    "if 'nocd-search-huggingface-mini-lm' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'nocd-search-huggingface-mini-lm',\n",
    "        dimension=model.get_sentence_embedding_dimension(),\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('nocd-search-huggingface-mini-lm')\n",
    "\n",
    "passages = get_text(blogs_df)  # generator that loads (query, passage) pairs\n",
    "blogs_df = blogs_df.replace({np.nan: ''})\n",
    "\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(passages), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(passages))\n",
    "    # get batch of lines and IDs\n",
    "    passage_batch = passages[i: i+batch_size]\n",
    "    ids_batch = [f\"{str(n)}_{model_name}\" for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    embeds = model.encode(passage_batch).tolist()\n",
    "    # prep metadata and upsert batch\n",
    "    metadata = [\n",
    "        {\n",
    "            'text': passage, \n",
    "            'paragraph_name': blogs_df[blogs_df['text'] == passage].iloc[0]['paragraph'], \n",
    "            'article_name': blogs_df[blogs_df['text'] == passage].iloc[0]['article'], \n",
    "            'model': model_name\n",
    "        } \n",
    "        for passage in passage_batch\n",
    "    ]\n",
    "    to_upsert = zip(ids_batch, embeds, metadata)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))\n",
    "\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [24:55<00:00, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 2048,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 4373}},\n",
      " 'total_vector_count': 4373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# upsert using OPENAI model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "import os\n",
    "import pinecone\n",
    "import time\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai_model_doc = 'text-search-babbage-doc-001'\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "\n",
    "test_embedding = openai.Embedding.create(input='test', engine=openai_model_doc)\n",
    "shape = [len(a['embedding']) for a in test_embedding['data']]\n",
    "\n",
    "if 'nocd-search-openai' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'nocd-search-openai',\n",
    "        dimension=shape[0],\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('nocd-search-openai')\n",
    "\n",
    "passages = get_text(blogs_df)  \n",
    "blogs_df = blogs_df.replace({np.nan: ''})\n",
    "\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(passages), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(passages))\n",
    "    # get batch of lines and IDs\n",
    "    passage_batch = passages[i: i+batch_size]\n",
    "    ids_batch = [f\"{str(n)}_{openai_model_doc}\" for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    res = openai.Embedding.create(input=passage_batch, engine=openai_model_doc)\n",
    "    embeds = [record['embedding'] for record in res['data']]\n",
    "    # prep metadata and upsert batch\n",
    "    metadata = [{'text': passage, 'paragraph_name': blogs_df[blogs_df['text'] == passage].iloc[0]['paragraph'], 'article_name': blogs_df[blogs_df['text'] == passage].iloc[0]['article'], 'model': openai_model_doc} for passage in passage_batch]\n",
    "    to_upsert = zip(ids_batch, embeds, metadata)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))\n",
    "    time.sleep(10)\n",
    "\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [13:18<00:00,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 2048,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 8746}},\n",
      " 'total_vector_count': 8746}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# upsert using COHERE model\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cohere\n",
    "\n",
    "import os\n",
    "import pinecone\n",
    "import time\n",
    "\n",
    "co = cohere.Client(os.getenv('COHERE_API_KEY'))\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "\n",
    "test_embedding = co.embed(texts=['hello', 'goodbye'], model='medium').embeddings\n",
    "shape = np.array(test_embedding).shape\n",
    "\n",
    "if 'nocd-search-openai' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'nocd-search-openai',\n",
    "        dimension=shape[1],\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('nocd-search-openai')\n",
    "\n",
    "passages = get_text(blogs_df)  \n",
    "blogs_df = blogs_df.replace({np.nan: ''})\n",
    "\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(passages), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(passages))\n",
    "    # get batch of lines and IDs\n",
    "    passage_batch = passages[i: i+batch_size]\n",
    "    ids_batch = [f\"{str(n)}_cohere-medium\" for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    embeds = co.embed(texts=passage_batch, model='medium').embeddings\n",
    "    # prep metadata and upsert batch\n",
    "    metadata = [\n",
    "        {\n",
    "            'text': passage, \n",
    "            'paragraph_name': blogs_df[blogs_df['text'] == passage].iloc[0]['paragraph'], \n",
    "            'article_name': blogs_df[blogs_df['text'] == passage].iloc[0]['article'], \n",
    "            'model': 'cohere-medium'\n",
    "        } \n",
    "            for passage in passage_batch\n",
    "    ]\n",
    "    to_upsert = zip(ids_batch, embeds, metadata)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))\n",
    "    time.sleep(5)\n",
    "\n",
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_url(passage):\n",
    "    sep = passage.split(',')\n",
    "    start = sep[0].split(' ')[:4]\n",
    "    end = sep[-1].split(' ')[-4:]\n",
    "\n",
    "    start = '%20'.join(start)\n",
    "    end = '%20'.join(end)\n",
    "\n",
    "    return start + ',' + end\n",
    "\n",
    "def convert_url_v2(passage):\n",
    "    sep = passage.split(',')\n",
    "    start = sep[0].split(' ')[:4]\n",
    "    end = sep[-1].split(' ')[-4:]\n",
    "    if len(start) < 2:\n",
    "        end = sep[-1].split(' ')[-6:]\n",
    "\n",
    "    start = '%20'.join(start)\n",
    "    end = '%20'.join(end)\n",
    "\n",
    "    return start + ',' + end\n",
    "\n",
    "def query_db(query, model, index, passages):\n",
    "    query_emb = model.encode(query, convert_to_tensor=True, show_progress_bar=False)\n",
    "    res = index.query(query_emb.tolist(), top_k=10, include_metadata=True)\n",
    "\n",
    "    nocd = 'https://www.treatmyocd.com'\n",
    "\n",
    "    print(f'Search Query: {query}\\n')\n",
    "    print('---------------------------------------------------------------------------------------------------------------------')\n",
    "    print('Results\\n')\n",
    "    for item in res.matches:\n",
    "        print(f\"Article: {nocd}{item['metadata']['article']}#:~:text={convert_url(passage_dict[int(item['id'])])}\")\n",
    "        print(f\"Paragraph Header: {item['metadata']['paragraph']}\")\n",
    "        print(f\"{item['score']} {passage_dict[int(item['id'])]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_gen = get_pairs(query_passage_df)\n",
    "passage_dict = {i: p for i, (q, p) in enumerate(pairs_gen)}\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    query = input(\"Search NOCD: \")\n",
    "    if query == 'quit': break\n",
    "    query_db(query=query, model=model, index=index, passages=passage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rezamohideen/myProjects/semantic-search/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu116'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "064c034f0f64e9400890b622a62d848169ff5f30e48a68a58b1f34188e0a2fb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
