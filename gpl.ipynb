{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: huggingface-hub>=0.4.0 in ./ENV/lib/python3.8/site-packages (from sentence-transformers) (0.9.1)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 42.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in ./ENV/lib/python3.8/site-packages (from sentence-transformers) (1.23.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.2 MB 57.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 43.4 MB 67.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 75.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: torch>=1.6.0 in ./ENV/lib/python3.8/site-packages (from sentence-transformers) (1.12.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.1 MB 42.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in ./ENV/lib/python3.8/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied, skipping upgrade: transformers<5.0.0,>=4.6.0 in ./ENV/lib/python3.8/site-packages (from sentence-transformers) (4.22.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in ./ENV/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in ./ENV/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.3.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in ./ENV/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.9 in ./ENV/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied, skipping upgrade: filelock in ./ENV/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
      "Requirement already satisfied, skipping upgrade: regex>=2021.8.3 in ./ENV/lib/python3.8/site-packages (from nltk->sentence-transformers) (2022.9.13)\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 7.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 78.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 50.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tokenizers!=0.11.3,<0.13,>=0.11.1 in ./ENV/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<3,>=2 in ./ENV/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in ./ENV/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.12)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in ./ENV/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.14)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in ./ENV/lib/python3.8/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=3.0.5,>=2.0.2 in ./ENV/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /home/ubuntu/gitrepos/semantic-search/ENV/bin/python3.8 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-wg2kq9lv/sentence-transformers/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-wg2kq9lv/sentence-transformers/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-lr2kw9a2\n",
      "       cwd: /tmp/pip-install-wg2kq9lv/sentence-transformers/\n",
      "  Complete output (6 lines):\n",
      "  usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: setup.py --help [cmd1 cmd2 ...]\n",
      "     or: setup.py --help-commands\n",
      "     or: setup.py cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for sentence-transformers\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for sentence-transformers\n",
      "Failed to build sentence-transformers\n",
      "Installing collected packages: click, joblib, nltk, scipy, threadpoolctl, scikit-learn, sentencepiece, pillow, torchvision, sentence-transformers\n",
      "    Running setup.py install for sentence-transformers ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed click-8.1.3 joblib-1.1.0 nltk-3.7 pillow-9.2.0 scikit-learn-1.1.2 scipy-1.9.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 threadpoolctl-3.1.0 torchvision-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-2.0.13-py3-none-any.whl (175 kB)\n",
      "\u001b[K     |████████████████████████████████| 175 kB 25.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting loguru>=0.5.0\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 8.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.4 in ./ENV/lib/python3.8/site-packages (from pinecone-client) (6.0)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in ./ENV/lib/python3.8/site-packages (from pinecone-client) (1.26.12)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./ENV/lib/python3.8/site-packages (from pinecone-client) (2.28.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./ENV/lib/python3.8/site-packages (from pinecone-client) (2.8.2)\n",
      "Collecting dnspython>=2.0.0\n",
      "  Downloading dnspython-2.2.1-py3-none-any.whl (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 62.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in ./ENV/lib/python3.8/site-packages (from pinecone-client) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./ENV/lib/python3.8/site-packages (from requests>=2.19.0->pinecone-client) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./ENV/lib/python3.8/site-packages (from requests>=2.19.0->pinecone-client) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./ENV/lib/python3.8/site-packages (from requests>=2.19.0->pinecone-client) (2.1.1)\n",
      "Requirement already satisfied: six>=1.5 in ./ENV/lib/python3.8/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Installing collected packages: loguru, dnspython, pinecone-client\n",
      "Successfully installed dnspython-2.2.1 loguru-0.6.0 pinecone-client-2.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pinecone-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what does ocd mean</td>\n",
       "      <td>One of the most helpful things in my own recov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>is it good to talk about an ocd</td>\n",
       "      <td>One of the most helpful things in my own recov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>does ocd really help recovery</td>\n",
       "      <td>One of the most helpful things in my own recov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what is being a positive person</td>\n",
       "      <td>There is something powerful about knowing that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>who is an inspirational person</td>\n",
       "      <td>There is something powerful about knowing that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            query  \\\n",
       "0           0               what does ocd mean   \n",
       "1           1  is it good to talk about an ocd   \n",
       "2           2    does ocd really help recovery   \n",
       "3           3  what is being a positive person   \n",
       "4           4   who is an inspirational person   \n",
       "\n",
       "                                             passage  \n",
       "0  One of the most helpful things in my own recov...  \n",
       "1  One of the most helpful things in my own recov...  \n",
       "2  One of the most helpful things in my own recov...  \n",
       "3  There is something powerful about knowing that...  \n",
       "4  There is something powerful about knowing that...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query_passage_df = pd.read_csv('query_passage.csv')\n",
    "query_passage_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/gitrepos/semantic-search/ENV/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 690/690 [00:00<00:00, 964kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:00<00:00, 113kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3.99k/3.99k [00:00<00:00, 3.85MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 548/548 [00:00<00:00, 427kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 100kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 265M/265M [00:04<00:00, 61.0MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 53.0/53.0 [00:00<00:00, 30.8kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 147kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 50.5MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 547/547 [00:00<00:00, 703kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 41.8MB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 229/229 [00:00<00:00, 190kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('msmarco-distilbert-base-tas-b')\n",
    "model.max_seq_length = 256\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "API_KEY = \"55e5d3b2-c5f7-494d-8323-3c79b45150a6\"\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=API_KEY,\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "# create a new genq index if does not already exist\n",
    "if 'negative-mine' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'negative-mine',\n",
    "        dimension=model.get_sentence_embedding_dimension(),\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('negative-mine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(df):\n",
    "    pairs = []\n",
    "    for index, row in df.iterrows():\n",
    "        pairs.append((row['query'], row['passage']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_gen = get_text()  # generator that loads (query, passage) pairs\n",
    "\n",
    "pairs = []\n",
    "to_upsert = []\n",
    "passage_batch = []\n",
    "id_batch = []\n",
    "batch_size = 64  # encode and upload size\n",
    "\n",
    "for i, (query, passage) in enumerate(pairs_gen):\n",
    "    pairs.append((query, passage))\n",
    "    # we do this to avoid passage duplication in the vector DB\n",
    "    if passage not in passage_batch: \n",
    "        passage_batch.append(passage)\n",
    "        id_batch.append(str(i))\n",
    "    # on reaching batch_size, we encode and upsert\n",
    "    if len(passage_batch) == batch_size:\n",
    "        embeds = model.encode(passage_batch).tolist()\n",
    "        # upload to index\n",
    "        index.upsert(vectors=list(zip(id_batch, embeds)))\n",
    "        # refresh batches\n",
    "        passage_batch = []\n",
    "        id_batch = []\n",
    "        \n",
    "# check number of vectors in the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "876a2fd22e9efeae2400b15fdef46235738e26446a244235c52059b002c44980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
