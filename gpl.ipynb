{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "blogs = pd.read_csv('blogs.csv')\n",
    "\n",
    "def get_text():\n",
    "    for index, row in blogs.iterrows():\n",
    "        if row['tag'] == 'p':\n",
    "            yield row['text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogs['num_words'] = blogs['text'].str.split().str.len()\n",
    "low_words = blogs[(blogs['num_words'] > 256) & (blogs['tag'] == 'p')]\n",
    "blogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rezamohideen/myProjects/semantic-search/ENV/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = 'doc2query/msmarco-t5-base-v1'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph:\n",
      "One of the most helpful things in my own recovery journey has been hearing about other people’s experiences with OCD. This might be because we relish in stories of triumph and are drawn toward people with shared experiences. I think this is true for many things in life. Personally, I learn and grow from these stories.\n",
      "\n",
      "Generated Queries:\n",
      "1: what helps with ocd recovery\n",
      "2: what is an ocd support group\n",
      "3: what helps ocd\n",
      "\n",
      "Paragraph:\n",
      "There is something powerful about knowing that someone else has walked the same path as you and that they have not only survived it, but possibly even thrived. I love hearing about the determination and grit of others who have faced similar obstacles. These stories of hope often inspired me to keep going, even when I didn’t think I could. \n",
      "\n",
      "Generated Queries:\n",
      "1: the effect of networking on personal success\n",
      "2: what is the meaning of being the victim of others\n",
      "3: what is the purpose of seeing another person walk the same path\n",
      "\n",
      "Paragraph:\n",
      "Support is a key piece of your recovery journey. That’s why at NOCD, we provide a safe space for people in the OCD community and their families to share their experiences in our virtual support groups, which are available to members doing exposure and response prevention (ERP) therapy with NOCD Therapy. There are over 25 different groups to join, with sessions nearly every day of the week, dealing with themes ranging from living with OCD to relapse prevention.\n",
      "\n",
      "Generated Queries:\n",
      "1: what is nocd therapy\n",
      "2: what is nocd support\n",
      "3: what is nocd therapy\n",
      "\n",
      "Paragraph:\n",
      "Support groups may help you realize that you are not alone. Many people have struggled with OCD for so long without proper treatment, going from therapist to therapist in hopes of finding relief, unable to get the specialized treatment needed to manage OCD. It’s often by hearing about other people’s experiences with successful treatment that they are able to learn about ERP therapy and finally get the help they need. And during treatment, support from others can help people keep going when things get challenging.  \n",
      "\n",
      "Generated Queries:\n",
      "1: what is erp therapy\n",
      "2: is ocd a mental illness\n",
      "3: what helps ocd\n",
      "\n",
      "Paragraph:\n",
      "This is one of the main reasons I continue to share my story: I want others to know that life can look very different from what it does in the throes of OCD. It may not seem like it at the moment, but there is hope after OCD—and you can live a life you may never have imagined. Similarly, support groups can provide a non-judgmental place where you can learn from others and healthily express your emotions.\n",
      "\n",
      "Generated Queries:\n",
      "1: how long can an ocd last\n",
      "2: what can I do after ocd\n",
      "3: do people have support groups\n",
      "\n"
     ]
    }
   ],
   "source": [
    "passages = get_text()\n",
    "for index, passage in enumerate(passages):\n",
    "    if index < 5:\n",
    "        # tokenize the passage\n",
    "        inputs = tokenizer(passage, return_tensors='pt')\n",
    "        # generate three queries\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs['input_ids'].cuda(),\n",
    "            attention_mask=inputs['attention_mask'].cuda(),\n",
    "            max_length=64,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            num_return_sequences=3)\n",
    "        print(\"Paragraph:\")\n",
    "        print(passage)\n",
    "\n",
    "        print(\"\\nGenerated Queries:\")\n",
    "        for i in range(len(outputs)):\n",
    "            query = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
    "            print(f'{i + 1}: {query}')\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('msmarco-distilbert-base-tas-b')\n",
    "model.max_seq_length = 256\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "with open('secret', 'r') as fp:\n",
    "    API_KEY = fp.read()  # get api key app.pinecone.io\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=API_KEY,\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "# create a new genq index if does not already exist\n",
    "if 'negative-mine' not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        'negative-mine',\n",
    "        dimension=model.get_sentence_embedding_dimension(),\n",
    "        metric='dotproduct',\n",
    "        pods=1  # increase for faster mining\n",
    "    )\n",
    "# connect\n",
    "index = pinecone.Index('negative-mine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_gen = get_text()  # generator that loads (query, passage) pairs\n",
    "\n",
    "pairs = []\n",
    "to_upsert = []\n",
    "passage_batch = []\n",
    "id_batch = []\n",
    "batch_size = 64  # encode and upload size\n",
    "\n",
    "for i, (query, passage) in enumerate(pairs_gen):\n",
    "    pairs.append((query, passage))\n",
    "    # we do this to avoid passage duplication in the vector DB\n",
    "    if passage not in passage_batch: \n",
    "        passage_batch.append(passage)\n",
    "        id_batch.append(str(i))\n",
    "    # on reaching batch_size, we encode and upsert\n",
    "    if len(passage_batch) == batch_size:\n",
    "        embeds = model.encode(passage_batch).tolist()\n",
    "        # upload to index\n",
    "        index.upsert(vectors=list(zip(id_batch, embeds)))\n",
    "        # refresh batches\n",
    "        passage_batch = []\n",
    "        id_batch = []\n",
    "        \n",
    "# check number of vectors in the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ENV': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "876a2fd22e9efeae2400b15fdef46235738e26446a244235c52059b002c44980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
